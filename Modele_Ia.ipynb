{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b208047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38cbbd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction d'activation\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb7e0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fonction d'initialisation\n",
    "def initialize(_nx, _nh, _ny):\n",
    "    W1 = np.random.randn(_nh, _nx)\n",
    "    b1 = np.zeros((_nx, 1))\n",
    "    W2 = np.random.randn(_ny, _nh)\n",
    "    b2 = np.zeros((_ny, 1))\n",
    "    \n",
    "    params = {\n",
    "        \"W1\":W1,\n",
    "        \"b1\":b1,\n",
    "        \"W2\":W2,\n",
    "        \"b2\":b2\n",
    "    }\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf564fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction de propagation\n",
    "def forward_propagation(X, params):\n",
    "\n",
    "    W1 = params[\"W1\"] #recuperation du parametre poids 1\n",
    "    b1 = params[\"b1\"] #recuperation du parametre biais 1\n",
    "    W2 = params[\"W2\"] #recuperation du parametre poids 2\n",
    "    b2 = params[\"b2\"] #recuperation du parametre biais 2\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1  #calcul de la premiere couche\n",
    "    A1 = np.tanh(Z1) #fonction d'activation de la premiere couche\n",
    "    Z2 = np.dot(W2, A1) + b2 #calcul de la deuxieme couche\n",
    "    A2 = sigmoid(Z2) #fonction d'activation de la deuxieme couche\n",
    "\n",
    "    cache = {\n",
    "        \"Z1\":Z1,\n",
    "        \"A1\":A1,\n",
    "        \"Z2\":Z2,\n",
    "        \"A2\":A2\n",
    "    }\n",
    "  \n",
    "    return A2, cache\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b90b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#realisation de la fonction de cout\n",
    "def compute_cost(A2, Y):\n",
    "    m = Y.shape[1]\n",
    "    logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(1-A2), 1-Y) \n",
    "    cost = - np.sum(logprobs)/m\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5e18a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fonction de retropropagation\n",
    "def backward_propagation(params, cache, X, Y):\n",
    "    m = X.shape[1]\n",
    "    W1 = params[\"W1\"]\n",
    "    W2 = params[\"W2\"]\n",
    "    A1 = cache[\"A1\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "    \n",
    "    dZ2 = A2 - Y #calcul de la derivee de Z2\n",
    "    dW2 = (1/m)*np.dot(dZ2, A1.T) #calcul de la derivee de W2\n",
    "    db2 = (1/m)*np.sum(dZ2, axis=1, keepdims=True) #calcul de la derivee de b2\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1-np.power(A1, 2)) #calcul de la derivee de Z1\n",
    "    dW1 = (1/m)*np.dot(dZ1, X.T) #calcul de la derivee de W1\n",
    "    db1 = (1/m)*np.sum(dZ1, axis=1, keepdims=True) #calcul de la derivee de b1\n",
    "    \n",
    "    grads = {\n",
    "        \"dW1\":dW1,\n",
    "        \"db1\":db1,\n",
    "        \"dW2\":dW2,\n",
    "        \"db2\":db2\n",
    "    }\n",
    "    return grads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04196ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(params, grads, learning_rate=1.2):\n",
    "    \n",
    "    # recuperation des parametres\n",
    "    W1 = params[\"W1\"]\n",
    "    b1 = params[\"b1\"]\n",
    "    W2 = params[\"W2\"]\n",
    "    b2 = params[\"b2\"]\n",
    "    \n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "    \n",
    "    # mise à jour des paramètres\n",
    "    W1 = W1 - dW1 * learning_rate \n",
    "    b1 = b1 - db1 * learning_rate\n",
    "    W2 = W2 - dW2 * learning_rate\n",
    "    b2 = b2 - db2 * learning_rate\n",
    "    \n",
    "    n_params = {\n",
    "        \"W1\": W1,\n",
    "        \"b1\": b1,\n",
    "        \"W2\": W2,\n",
    "        \"b2\": b2\n",
    "    }\n",
    "    \n",
    "    return n_params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a843901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction de d'entrainement\n",
    "def entrainement(X, Y, n_e, n_c, n_s, num_iterations,  display_cost=False)-> dict : \n",
    "   \n",
    "    params = initialize(n_e, n_c, n_s)\n",
    "    for i in range(0, num_iterations+1):\n",
    "        A2, cache = forward_propagation(X, params)\n",
    "        cost = compute_cost(A2, Y)\n",
    "        grads = backward_propagation(params, cache, X, Y)\n",
    "        params = update_parameters(params, grads)\n",
    "        if i%100==0 and display_cost:\n",
    "            print(\"Le cout après iteration numero %i est : %f\" %(i, cost))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36923fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction de prediction\n",
    "def predict(params, X):\n",
    "    \n",
    "    A2, cache = forward_propagation(X, params)\n",
    "    predictions = np.round(A2)\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7c5b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction de precision\n",
    "def precision(predictions, Y):\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    precision = np.sum((predictions == Y)/m)\n",
    "    return str(precision*100) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00496ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tester le ou exclusif en demandant à l'utilisateur de saisir  a et b\n",
    "\n",
    "def test_xor():\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            a = int(input(\"Saisir la valeur de a: \"))\n",
    "            if a not in [0, 1]:\n",
    "                raise ValueError(\"Veuillez saisir 0 ou 1\")\n",
    "            \n",
    "            b = int(input(\"Saisir la valeur de b: \"))\n",
    "            if b not in [0, 1]:\n",
    "                raise ValueError(\"Veuillez saisir 0 ou 1\")\n",
    "            \n",
    "            break  # sortir de la boucle while si tout s'est bien passé\n",
    "        \n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Vous avez interrompu le programme\")\n",
    "        \n",
    "        except EOFError:\n",
    "            print(\"Vous avez interrompu le programme\")\n",
    "    \n",
    "    X = np.array([[a], [b]])\n",
    "    Y = np.array([[a^b]])\n",
    "    params = entrainement(X, Y, 2, 2, 1, 1000)\n",
    "    predictions = predict(params, X)\n",
    "    print(\"La prediction est: \", predictions)\n",
    "    print(\"La precision est: \", precision(predictions, Y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751dcb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
